{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "final_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6muhef1exgm"
      },
      "source": [
        "import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkoZ8ZxKd-yG",
        "outputId": "4e8d7834-7c17-4d69-9e4d-06322806accd"
      },
      "source": [
        "!pip install pytorch-transformers\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp\n",
        "!pip install pytorch_pretrained_bert\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-transformers\n",
            "  Downloading pytorch_transformers-1.2.0-py3-none-any.whl (176 kB)\n",
            "\u001b[K     |████████████████████████████████| 176 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (4.62.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 40.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (1.9.0+cu102)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2.23.0)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.18.40-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 50.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 17.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.0.0->pytorch-transformers) (3.7.4.3)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 8.1 MB/s \n",
            "\u001b[?25hCollecting botocore<1.22.0,>=1.21.40\n",
            "  Downloading botocore-1.21.40-py3-none-any.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 25.0 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting urllib3<1.27,>=1.25.4\n",
            "  Downloading urllib3-1.26.6-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 48.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.40->boto3->pytorch-transformers) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.40->boto3->pytorch-transformers) (1.15.0)\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 45.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-transformers) (2021.5.30)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->pytorch-transformers) (7.1.2)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, sentencepiece, sacremoses, boto3, pytorch-transformers\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.18.40 botocore-1.21.40 jmespath-0.10.0 pytorch-transformers-1.2.0 s3transfer-0.5.0 sacremoses-0.0.45 sentencepiece-0.1.96 urllib3-1.25.11\n",
            "Collecting pytorch-pretrained-bert\n",
            "  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n",
            "\u001b[K     |████████████████████████████████| 123 kB 6.7 MB/s \n",
            "\u001b[?25hCollecting pytorch-nlp\n",
            "  Downloading pytorch_nlp-0.5.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 7.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.9.0+cu102)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.18.40)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (4.62.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-pretrained-bert) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.7.4.3)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.5.0)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.40 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (1.21.40)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch-pretrained-bert) (0.10.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.40->boto3->pytorch-pretrained-bert) (1.25.11)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.40->boto3->pytorch-pretrained-bert) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.40->boto3->pytorch-pretrained-bert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch-pretrained-bert) (2.10)\n",
            "Installing collected packages: pytorch-pretrained-bert, pytorch-nlp\n",
            "Successfully installed pytorch-nlp-0.5.0 pytorch-pretrained-bert-0.6.2\n",
            "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.7/dist-packages (0.6.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.19.5)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.9.0+cu102)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (4.62.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (1.18.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n",
            "Requirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.5.0)\n",
            "Requirement already satisfied: botocore<1.22.0,>=1.21.40 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (1.21.40)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from boto3->pytorch_pretrained_bert) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.40->boto3->pytorch_pretrained_bert) (2.8.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/dist-packages (from botocore<1.22.0,>=1.21.40->boto3->pytorch_pretrained_bert) (1.25.11)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.40->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->pytorch_pretrained_bert) (2021.5.30)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JGdQKjvahwLL"
      },
      "source": [
        "# Load twitter dataset  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uk8Vy4YYdDkk",
        "outputId": "9858adba-fcb5-4833-8500-7543b642fdcb"
      },
      "source": [
        "pd.set_option('display.max_colwidth', None)\n",
        "data = pd.read_excel(\"final_data.xlsx\")\n",
        "#data = data.sample(n = 100)\n",
        "print('We have',len(data), 'tweet in the data')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 439 tweet in the data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueYh3bwizmcm",
        "outputId": "6f222d02-c8a5-4079-d533-29923bb97c9e"
      },
      "source": [
        "data = data[['preprocess_tweets','object','emojis']]\n",
        "data = data.dropna()\n",
        "labels = data.emojis.values\n",
        "print('We have',len(data), 'not nan tweet in the data')\n",
        "#data.head(10)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 428 not nan tweet in the data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I1RcJOE8zmcm",
        "outputId": "980ef401-d34e-4df2-f3e5-1a1a821c2be6"
      },
      "source": [
        "# number of sentense for each emoji\n",
        "print(data['emojis'].value_counts())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2     13\n",
            "0      9\n",
            "8      8\n",
            "1      7\n",
            "18     6\n",
            "4      6\n",
            "6      5\n",
            "7      5\n",
            "12     5\n",
            "19     4\n",
            "10     4\n",
            "15     4\n",
            "16     4\n",
            "9      4\n",
            "13     3\n",
            "14     3\n",
            "11     2\n",
            "5      2\n",
            "3      2\n",
            "17     2\n",
            "Name: emojis, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmzT4Rdgzmcn"
      },
      "source": [
        "# Train Topic Model (LDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXiHEat_iU2M"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer(analyzer='word',       \n",
        "                             min_df=1,                         # minimum reqd occurences of a word \n",
        "                             stop_words='english',             # remove stop words\n",
        "                             lowercase=True,                   # convert all words to lowercase\n",
        "                             token_pattern='[a-zA-Z0-9]{3,}',  # num chars > 3\n",
        "                             max_features=1000,                # max number of uniq words\n",
        "                            )\n",
        "\n",
        "data_vectorized1 = vectorizer.fit_transform(data['preprocess_tweets'])\n",
        "data_vectorized2 = vectorizer.fit_transform(data['object'])"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLUhIdhE0Nsg",
        "outputId": "17c64c0b-c21c-4764-e922-8537970d76ca"
      },
      "source": [
        "print(data_vectorized1.shape)\n",
        "print(data_vectorized2.shape)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(428, 1000)\n",
            "(428, 1000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HvxQbfIXibMa"
      },
      "source": [
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "lda_model = LatentDirichletAllocation(n_components=90,           # Number of topics\n",
        "                                      learning_method='online',\n",
        "                                      random_state=0,            # Random state\n",
        "                                      n_jobs = -1                # Use all available CPUs\n",
        "                                     )\n",
        "lda_output = lda_model.fit_transform(np.concatenate((data_vectorized1.toarray(),data_vectorized2.toarray())))"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XquVbmpuiknH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a415e5-679b-4518-d9b3-d6e4ee68576f"
      },
      "source": [
        "def predict_topic(text):\n",
        "\n",
        "    # Step 1: Vectorize transform\n",
        "    mytext_4 = vectorizer.transform(text)\n",
        "\n",
        "    # Step 2: LDA Transform\n",
        "    topic_probability_scores = lda_model.transform(mytext_4)\n",
        "\n",
        "    return topic_probability_scores\n",
        "\n",
        "prob_scores_q1 = predict_topic(text = data['preprocess_tweets'])\n",
        "print(prob_scores_q1.shape)\n",
        "prob_scores_q2 = predict_topic(text = data['object'])\n",
        "print(prob_scores_q2.shape)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(428, 90)\n",
            "(428, 90)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNKzSAL9zmcq"
      },
      "source": [
        "# Preparing data to enter the BERT network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5zkKF7wjkra"
      },
      "source": [
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# function to tokenize and generate input ids for the tokens\n",
        "# returns a list of input ids\n",
        "def prep_data(ques1, ques2):\n",
        "    \n",
        "  all_input_ids = []\n",
        "  \n",
        "  for (q1,q2) in zip(ques1, ques2):\n",
        "    \n",
        "    # first sentence is appended with [CLS] and [SEP] in the beginning and end\n",
        "    q1 = '[CLS] ' + q1 + ' [SEP] '\n",
        "    tokens = tokenizer.tokenize(q1)\n",
        "    \n",
        "    # 0 denotes first sentence\n",
        "    seg_ids = [0] * len(tokens)\n",
        "    \n",
        "    # second sentence is appended with [SEP] in the end\n",
        "    #print(q2.type)\n",
        "    q2 = q2 + ' [SEP] '\n",
        "    tok_q2 = tokenizer.tokenize(q2)\n",
        "    \n",
        "    # seg ids is appended with 1 to denote second sentence\n",
        "    seg_ids += [1] * len(tok_q2)\n",
        "    \n",
        "    # first and second sentence tokens are appended together\n",
        "    tokens += tok_q2\n",
        "    \n",
        "    # input ids are generated for the tokens (one question pair)\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # input ids are stored in a separate list\n",
        "    all_input_ids.append(input_ids)\n",
        "    \n",
        "  return all_input_ids\n",
        "\n",
        "all_input_ids = prep_data(data['preprocess_tweets'].values, data['object'].values)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ev7pAfiOjtW9"
      },
      "source": [
        "# pad sentence to have equal size \n",
        "max_len = 0\n",
        "for i in all_input_ids: \n",
        "    if max_len < len(i):\n",
        "        max_len = len(i)\n",
        "\n",
        "# max len of sentences \n",
        "n = max_len\n",
        "pad_input_ids = pad_sequences(all_input_ids, maxlen=n, dtype=\"long\", truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiHMLw55juK0"
      },
      "source": [
        "# Create attention masks\n",
        "attention_masks = []\n",
        "# Create a mask of 1s for each token followed by 0s for padding\n",
        "for seq in pad_input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amYMo6_-dDkv"
      },
      "source": [
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmQd3_0udDkv",
        "outputId": "0c56921b-67ca-454d-d02b-be18a5b046a8"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfmkNGzGttJx"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from pytorch_pretrained_bert import  BertModel\n",
        "\n",
        "    \n",
        "class my_BERT(nn.Module):\n",
        "    ''' A sequence to sequence model with attention mechanism. '''\n",
        "    def __init__(self,emb_size, topic_num):\n",
        " \n",
        "        super().__init__()\n",
        "        self.tbert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.trg_word_prj = nn.Linear(emb_size + topic_num + topic_num, 20, bias=False)\n",
        "\n",
        "    def forward(self, b_input_ids, attention_mask, topics, token_type_ids=None):\n",
        "        \n",
        "        _,pooled_layer = self.tbert(b_input_ids,attention_mask)\n",
        "        out = self.trg_word_prj(torch.cat((pooled_layer,topics),-1))\n",
        "        return  F.softmax(out)\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2FNz7RJxvRw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "484ae492-f0d6-494f-8f48-aa5a8bb1f5d9"
      },
      "source": [
        "emb_size = 768\n",
        "topic_num = 90\n",
        "model = my_BERT(emb_size,topic_num)\n",
        "model.to(device)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 407873900/407873900 [00:11<00:00, 36682325.69B/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "my_BERT(\n",
              "  (tbert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): BertLayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): BertLayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): BertLayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (trg_word_prj): Linear(in_features=948, out_features=20, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thBjna4RymUB"
      },
      "source": [
        "# Use train_test_split to split our data into train and validation sets for training\n",
        "train_inputs,validation_inputs,train_labels,validation_labels=train_test_split(np.concatenate((pad_input_ids,prob_scores_q1,prob_scores_q2),axis=-1),labels,random_state=2018,test_size=0.2,)\n",
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, pad_input_ids,random_state=2018, test_size=0.2)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnCyvFSzymUC"
      },
      "source": [
        "train_topics = torch.tensor(train_inputs[:,n:])\n",
        "train_inputs = torch.tensor(train_inputs[:,0:n])\n",
        "\n",
        "validation_topics = torch.tensor(validation_inputs[:,n:])\n",
        "validation_inputs = torch.tensor(validation_inputs[:,0:n])\n",
        "\n",
        "train_labels = torch.tensor(train_labels)\n",
        "validation_labels = torch.tensor(validation_labels)\n",
        "\n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_masks = torch.tensor(validation_masks)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1ag6g9KymUC"
      },
      "source": [
        "# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n",
        "# with an iterator the entire dataset does not need to be loaded into memory\n",
        "\n",
        "batch_size = 2\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels,train_topics)\n",
        "train_dataloader = DataLoader(train_data,batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels,validation_topics)\n",
        "validation_dataloader = DataLoader(validation_data, batch_size=batch_size)\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C15fWTEM2kxN"
      },
      "source": [
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'gamma', 'beta']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hf5IXVW63dpX",
        "outputId": "f5b3e29f-36e6-49ff-f7ec-c9c77821d329"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = BertAdam(optimizer_grouped_parameters,lr=2e-5,warmup=.1)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "t_total value of -1 results in schedule not being applied\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TDbMS5rd1kfZ",
        "outputId": "c9cf6f5f-1edf-4ffa-9289-19db75e56062"
      },
      "source": [
        "train_loss_set = []\n",
        "train_acc_set = []\n",
        "\n",
        "\n",
        "epochs = 20\n",
        "from tqdm import trange \n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "\n",
        "# trange is a tqdm wrapper around the normal python range\n",
        "for _ in trange(epochs, desc=\"Epoch\"):\n",
        "    \n",
        "  # Training \n",
        "  model.train()\n",
        "  \n",
        "  # Tracking variables\n",
        "  tr_loss = 0\n",
        "  train_accuracy = 0\n",
        "  nb_tr_examples, nb_tr_steps = 0, 0\n",
        "  \n",
        "  # Train the data for one epoch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    \n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels, b_topics= batch\n",
        "   \n",
        "    # Clear out the gradients\n",
        "    optimizer.zero_grad()\n",
        "     \n",
        "    ###############Bug fix code####################\n",
        "    b_input_ids = b_input_ids.type(torch.LongTensor)\n",
        "    b_input_mask = b_input_mask.type(torch.LongTensor)\n",
        "    b_labels = b_labels.type(torch.LongTensor)\n",
        "    b_input_ids = b_input_ids.to(device)\n",
        "    b_input_mask = b_input_mask.to(device)\n",
        "    b_labels = b_labels.to(device)\n",
        "    ###############Bug fix code####################\n",
        "\n",
        "    # Forward pass\n",
        "    outputs = model(b_input_ids,b_input_mask,b_topics.float().to(device))\n",
        "    loss = criterion(outputs, b_labels)\n",
        "    train_loss_set.append(loss.item())    \n",
        "\n",
        "\n",
        "    \n",
        "    # Backward pass\n",
        "    loss.backward()\n",
        "    \n",
        "    # Update parameters and take a step using the computed gradient\n",
        "    optimizer.step()\n",
        "    \n",
        "    \n",
        "    # train accuracy\n",
        "    logitss = outputs.detach().cpu().numpy()\n",
        "    label_idss = b_labels.detach().cpu().numpy()\n",
        "    tmp_train_accuracy = accuracy(logitss, label_idss)\n",
        "    train_acc_set.append(tmp_train_accuracy)    \n",
        "    train_accuracy += tmp_train_accuracy\n",
        "\n",
        "    # train accuracy\n",
        "    tr_loss += loss.item()\n",
        "    nb_tr_examples += b_input_ids.size(0)\n",
        "    nb_tr_steps += 1\n",
        "\n",
        "  print(\"Train loss: {}\".format(tr_loss/nb_tr_steps),\n",
        "        \"---train Accuracy: {}\".format(train_accuracy/nb_tr_steps))\n",
        "      \n",
        "  # Validation\n",
        "\n",
        "  # Put model in evaluation mode to evaluate loss on the validation set\n",
        "  model.eval()\n",
        "\n",
        "  # Tracking variables \n",
        "  eval_loss, eval_accuracy ,eval_f1= 0, 0, 0\n",
        "  nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "  # Evaluate data for one epoch\n",
        "  for batch in validation_dataloader:\n",
        "    \n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    \n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_labels, b_topics = batch\n",
        "    \n",
        "    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n",
        "    with torch.no_grad():\n",
        "      ###############Bug fix code####################\n",
        "      b_input_ids = b_input_ids.type(torch.LongTensor)\n",
        "      b_input_mask = b_input_mask.type(torch.LongTensor)\n",
        "      b_input_ids = b_input_ids.to(device)\n",
        "      b_input_mask = b_input_mask.to(device)\n",
        "      ###############Bug fix code####################\n",
        "      # Forward pass, calculate logit predictions\n",
        "      logits = model(b_input_ids,b_input_mask,b_topics.float().to(device))\n",
        "    \n",
        "    # Move logits and labels to CPU\n",
        "    losss = criterion(logits, b_labels)\n",
        "    eval_loss += losss.item()\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.detach().cpu().numpy()\n",
        "    tmp_eval_accuracy = accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    ftat_digit = np.argmax(logits, axis=1).flatten()\n",
        "    tmp_eval_f1= f1_score(ftat_digit, label_ids, average=\"micro\" )\n",
        "    eval_f1 += tmp_eval_f1\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "  print(\"Validation loss: {}\".format(eval_loss/nb_eval_steps),\n",
        "        \"---Validation Accuracy: {}\".format(eval_accuracy/nb_eval_steps),\n",
        "        \"----valdisation F1 score:{}\".format(eval_f1/nb_eval_steps))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   0%|          | 0/20 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss: 2.966718786641171 ---train Accuracy: 0.08771929824561403\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:   5%|▌         | 1/20 [01:06<21:11, 66.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.9693891336751537 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.96245771402504 ---train Accuracy: 0.09941520467836257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  10%|█         | 2/20 [02:13<20:00, 66.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.9694983903751817 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.961652992761623 ---train Accuracy: 0.09064327485380116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  15%|█▌        | 3/20 [03:20<18:53, 66.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.969108736792276 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.960423511371278 ---train Accuracy: 0.1023391812865497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  20%|██        | 4/20 [04:26<17:46, 66.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.9696086783741795 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.960533082136634 ---train Accuracy: 0.09649122807017543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  25%|██▌       | 5/20 [05:33<16:40, 66.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.968119321867477 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.9616108456550285 ---train Accuracy: 0.09649122807017543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  30%|███       | 6/20 [06:40<15:33, 66.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.9695951716844426 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.9599818416506225 ---train Accuracy: 0.09941520467836257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  35%|███▌      | 7/20 [07:46<14:27, 66.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.969505237978558 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.959172975250155 ---train Accuracy: 0.0935672514619883\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  40%|████      | 8/20 [08:53<13:20, 66.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.9668157821477847 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.962558038053457 ---train Accuracy: 0.09941520467836257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  45%|████▌     | 9/20 [10:00<12:13, 66.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.9699644099834352 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.958747018847549 ---train Accuracy: 0.1111111111111111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  50%|█████     | 10/20 [11:06<11:05, 66.58s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.970465992772302 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.958270848145959 ---train Accuracy: 0.1023391812865497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  55%|█████▌    | 11/20 [12:13<09:59, 66.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.969667129738386 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.9586363535875466 ---train Accuracy: 0.10526315789473684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  60%|██████    | 12/20 [13:20<08:53, 66.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.9698661427165187 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.9603535292441383 ---train Accuracy: 0.1023391812865497\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  65%|██████▌   | 13/20 [14:26<07:46, 66.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.9689720120540883 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.9578690821664377 ---train Accuracy: 0.10818713450292397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  70%|███████   | 14/20 [15:33<06:40, 66.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.9689606677654177 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.9598494663573147 ---train Accuracy: 0.09941520467836257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  75%|███████▌  | 15/20 [16:40<05:34, 66.85s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.9693539419839547 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.9597708049573397 ---train Accuracy: 0.10818713450292397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  80%|████████  | 16/20 [17:47<04:27, 66.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.9699646539466324 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.9591374383335225 ---train Accuracy: 0.09064327485380116\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  85%|████████▌ | 17/20 [18:54<03:20, 66.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.969890211903772 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.959292765946416 ---train Accuracy: 0.09649122807017543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  90%|█████████ | 18/20 [20:01<02:13, 66.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.9698125262593114 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.960267536821421 ---train Accuracy: 0.09649122807017543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch:  95%|█████████▌| 19/20 [21:08<01:06, 66.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.9705634006234103 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n",
            "Train loss: 2.959101313038876 ---train Accuracy: 0.09649122807017543\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch: 100%|██████████| 20/20 [22:15<00:00, 66.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation loss: 2.9702373327210894 ---Validation Accuracy: 0.10465116279069768 ----valdisation F1 score:0.10465116279069768\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "EldyM0D9ZG3c",
        "outputId": "383dcc72-3db0-4c29-d8a6-e9e527e5c51b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(train_loss_set)\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('loss')\n",
        "plt.title('Train-loss')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Train-loss')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "uzn6u5Nxeqj3",
        "outputId": "ac5a1a2e-deb8-4912-f309-8b7e9d9b07fe"
      },
      "source": [
        "plt.plot(train_acc_set)\n",
        "plt.xlabel('iteration')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('Train-accuracy')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Train-accuracy')"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEWCAYAAABi5jCmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debwcZZ3v8c+XJCRssiUsk0QSIC7BBWJk4LqhILKoqCNXUEZwAUdF8Y6o8eogw+gV0dEZZ3BBZRVBQGRyJcCgAgIC5gQIhEDkEIxJWHIgCwkhZPvNH1UHuk+6z6neu05936/XeaVrebp/9aS6f1XPU/WUIgIzM7N+W3U6ADMz6y5ODGZmVsaJwczMyjgxmJlZGScGMzMr48RgZmZlnBisMCRdJ+nETsdh1u3k+xism0laUzK5LfA8sCmd/kREXNr+qMyGNycGyw1JfwE+HhG/rbBsZERsbH9U7THct8+6i5uSLJckHSJpiaQvSXoCuEDSzpJ+I6lP0or09YSSMjdL+nj6+iRJt0n6Trruo5KOHOTz9pH0e0lPS3pK0qWSdipZPlHS1elnPy3pP0uWnSzpQUmrJc2XNC2dH5L2LVnvQklfb2D7dpF0gaTH0uXXpPPnSXpXyXqj0m04oLH/BRuunBgsz/YAdgH2Ak4h2Z8vSKdfCjwH/GfV0vC3wAJgLHAO8DNJqrKugG8CfwO8EpgInAkgaQTwG2ARMAkYD1yeLjs2Xe/DwEuAdwNPt2j7LiFpbtsP2A34Xjr/YuCEkvWOAh6PiHsyxmFFExH+818u/oC/AIelrw8B1gNjBll/f2BFyfTNJE1RACcBvSXLtgUC2CNjLO8B7klfHwz0ASMrrHcDcFqV9whg35LpC4Gv17N9wJ7AZmDnCuv9DbAaeEk6fRXwxU7/f/qve/98xmB51hcR6/onJG0r6ceSFkl6BvgDsFN6RF/JE/0vImJt+nJ7SW+StCb9eyB9790lXS5pafrePyc504Dk7GFRVO4DmAg80obtmwgsj4gVA98kIh4Dbgf+Lm3+OhJwp71V5cRgeTbwyonPAy8H/jYiXgK8OZ1frXmo8ptG3BoR26d/+6Wz/1/6ea9O3/uEkvddDLxU0sgKb7cY2KfKR60lOVPpt8fAUAZMD7Z9i4FdSvs9BrgojflY4I6IWFplPTMnBhtWdiBpd18paRfga01+7zXAKknjgS+ULPsT8DhwtqTtJI2R9IZ02U+B0yW9Tol9Je2VLrsX+KCkEZKOAN6SIYaK2xcRjwPXAT9IO6lHSXpzSdlrgGnAaSR9DmZVOTHYcPJvwDbAU8CdwPVNfO9/JvlhXQVcC1zdvyAiNgHvAvYF/gosAT6QLrsS+AbwC5J2/mtIOpQh+ZF+F7AS+FC6bDBDbd/fAxuAh4BlwOdKYnwO+BUwuTR2s0p8H4NZQUg6A3hZRJww5MpWaJXaRM1smEmbnj5GclZhNig3JZkNc5JOJumcvi4i/tDpeKz7uSnJzMzK+IzBzMzK5K6PYezYsTFp0qROh2Fmlitz5sx5KiLGZVk3d4lh0qRJ9PT0dDoMM7NckbQo67puSjIzszJODGZmVsaJwczMyjgxmJlZGScGMzMr07LEIOl8ScskzauyXJK+L6lX0n39jzs0M7POauUZw4XAEYMsPxKYkv6dAvywhbGYmVlGLUsM6ZgsywdZ5Rjg4kjcSfIkqj1bFU+jZt3/OMufXV9X2dl/Wc6fn1xdV9lHn3qWP/Y+VVfZ1es28F/31vc8lojgV3OWsG7DprrK37xgGYuXrx16xQrmLV3FPX/d4kFkmSx7Zh03zn+yrrIbNm3mip7FbN5c3zAx13VoH2lEtX1k3YZNXDVnCYMNmdPoPnLLn/vq3kceeKwz+8jGDu4j7dTJPobxJAN79VuSztuCpFMk9Ujq6evra0twpfpWP8+nLr2bUy6u78a6Y390B4d/r76xy976nZv54E/vqqvsjF/dz2mX38v8x56pueytDz/F56+cyzdnPVjXZ590wWwO++4tdZV953/cxnt/8Me6yh774zs4+eKeur64P7l1IV+86j6umrOk5rJPr3meT156Nx+/aHbNZaGxfaQRM65O9pF5S1eVzT/7uoc4/cq5/OHh6gclt/Um+8g3rq1vHznx/D9x6L/Wt48c/f3695EPnHcnJ1/cw6Y69pGf3vYoX7zqPq6cs3jolQdY/ux6Pnnp3Xz0wvr2kXbKRedzRJwXEdMjYvq4cZnu6G6qDZs2A7B05XNt/+xGPLYqife5Oo7oVq9LHl/ct+b5uj//+Y2b6y5br0VPJ0egqulhnonla5IjuVXPbai57IZNyY9M3vaRJ1Ylj5QeeNS/bHUyf826So+xpmxZ3+r695H1mzqxjzxbd9n+o/2Va2vfRzbm6Hekk4lhKckDzPtNSOeZmVkHdTIxzAQ+nF6ddBCwKn1urZmZdVDLBtGTdBlwCDBW0hKSB5ePAoiIHwGzgKOAXmAt8JFWxdIs+X10Rf2B53WbI+prTgKIItZX1flDb1Aj9dVJScd6fTtJI1uch32kZYkhIo4fYnkAn27V5zdTvT8wndZI2LndZtX/xWtkm3NbX1XnD71Bud3mBnaShjY5R/WVi85nMzNrHycGMzMr48SQQR7aBCsZ7u2glTQSd6fKdlIx95EG+pAa+uBGCreXE4MNSzn6Dpp1HSeGDHLbydZI2bxuc4c6kHNbX42Uzes2NxC4O5/NzKyQnBjMzKyME0MN8nsjT2fKdlJDHYyN1Ff9RTuq2jZnqYvc7iONlB3mvdBODBlkudmnG3WsLbWDGmszL2B9Vb/DLUvpJkbSPp3qJ8jT74gTg5mZlXFiMDOzMk4MNix1fyuudVpe+0bawYnBzMzKODGYmVkZJwYzMyvjxGBmVbkZvpicGGqQ186qhm7kyelPQ6duUsvtPjIg8FquuM/pJjf2pL5h/pQ/J4YMcjtYWCNl87rNHiCtJo3cdJXffaSBsgWpLycGMzMr48RgZmZlnBhsWMpr34i1Tx7a+jvFicHMzMo4MZiZWRknBjMzK+PEUIO8NkkW80E9nSmb172kWtRZHniU132kEcP9YU5ODBnk6PLjMo1dN53PrfZDWGpUJews94PkdIs7di9CnurLicHMzMo4MZiZWRknhgzy0CZYidvK21c4t/dNDPO28ko6Nc5RnurLicHMCqmIneZZOTFkkKdOo1LufG5f4eHW+dzioh3lzuehtTQxSDpC0gJJvZJmVFj+Ukk3SbpH0n2SjmplPGZmNrSWJQZJI4BzgSOBqcDxkqYOWO2rwBURcQBwHPCDVsVjZmbZtPKM4UCgNyIWRsR64HLgmAHrBPCS9PWOwGMtjKdheW2TzHKTUtWyTYyjnRrrJBzeD2GpZGDctTV75HOjO3XBQCPfx3ZpZWIYDywumV6Szit1JnCCpCXALOAzld5I0imSeiT19PX1tSLWweWpcbBEUR4qUsoPYalNYw9zKt5GF6W+Ot35fDxwYURMAI4CLpG0RUwRcV5ETI+I6ePGjWt7kGZmRdLKxLAUmFgyPSGdV+pjwBUAEXEHMAYY28KYzMxsCK1MDLOBKZImS9qapHN55oB1/gocCiDplSSJoQNtRUPo/ibBitxWXmPZItZXI2ULuNFFqa+WJYaI2AicCtwAPEhy9dEDks6S9O50tc8DJ0uaC1wGnBR5qj3rWrm9E9naxr801Y1s5ZtHxCySTuXSeWeUvJ4PvKGVMTRFfvqMyhSyM9WdzzUpSmdqGXc+D6nTnc9mZtZlnBjMrCo3txSTE0NN8vktaazDrGlhtFWnnuCW0+raok+mllaP3O4jjZQd5jeNOjFk4AHS8sMDpNWmkNvcSNmC1JcTg5mZlXFiyCC3lz66SaS2skWsryJucyNlC1JfTgw2LOXpS2id4VumqnNiyMB9DPnhPobaFHKbGylbkPpyYjAzszJODGZmVsaJwcyqyu2FF9YQJ4Ya5LWvqrG487nRnepYzG2HZgNPcMvpFnfu6qQcVJgTQwY5GvuqTFEG/CrjAdJqUsiBAzs00GKeODGYmVkZJ4YM8nDqV0lRHipSxg9hqUkhH07UqYc51f+xbefEYMNSnr6E1hl5TWzt4MSQQW7bUhspW8CNzukWN8R9DDWWLche4sRgZmZlnBjMrCo3txSTE4OZbSG3TYnWFE4MNcjrwZOvPKm1bDGuPClVxCuyfAVbdU4Mw1hRRoIs1amRM/OqoX0kp/VVxA73WjkxZJCDBF9RUR4qUsoPYalNtW3OclSb2+9Fpx7mlKMKc2KoQV4PFnyEVJtG2tfzWl2FvLS5AcO9vpwYapCffF+uiH0MDbUfu4+hph+vPB0Jl+rUXcx5qC8nhmHMfQw1ls3rRjfAfQw1ls3pNtfKicHMzMo4MZhZVTlo9bAWcGKoQR7aBisq4tU2HbvypP6ynTQw7kI8qKdD/895qC8nhmGsiG2pHiCtNkWsryL2vdWqpYlB0hGSFkjqlTSjyjr/W9J8SQ9I+kUr4zEzs6GNbNUbSxoBnAu8HVgCzJY0MyLml6wzBfgy8IaIWCFpt1bF04i8PhC9iJepduwhLK6v3OhUM1CeaquVZwwHAr0RsTAi1gOXA8cMWOdk4NyIWAEQEctaGE/D8nBjSkU+da5JIS/h9D5Sk+FeX5kSg6SrJR0tqZZEMh5YXDK9JJ1X6mXAyyTdLulOSUdU+fxTJPVI6unr66shhOZy53N+dKxjMacVNtw7Uyvx8CnVZf2h/wHwQeBhSWdLenmTPn8kMAU4BDge+ImknQauFBHnRcT0iJg+bty4Jn308OfO5xrL5uJYrrmKWF/D/Wi/GTIlhoj4bUR8CJgG/AX4raQ/SvqIpFFVii0FJpZMT0jnlVoCzIyIDRHxKPBnkkRhZl0gD0e31nyZm4Yk7QqcBHwcuAf4d5JEcWOVIrOBKZImS9oaOA6YOWCda0jOFpA0lqRpaWH28M2sJYpyaGwVZboqSdKvgZcDlwDviojH00W/lNRTqUxEbJR0KnADMAI4PyIekHQW0BMRM9Nlh0uaD2wCvhARTze2Sa2T16On4T7gVyWdunokv/VVxCuyGhlEb3h3MmS9XPX7EXFTpQURMb1aoYiYBcwaMO+MktcB/GP6Z01WyKtrCtiv0oiG+glyWl8NhV2QnSRrU9LU0k5hSTtL+lSLYjIzsw7KmhhOjoiV/RPpfQcntyakLpSDU79KCnnZZafGSMrpTjLcm0QqaSjsRpqfclRfWRPDCJXc3ZXe1bx1a0LqXnk9iRzuT5tqtiLWl5vgajPcm+Cy9jFcT9LR/ON0+hPpvELJUcIvU8jO1A49hS239VXEzueGyg7vM62sieFLJMngk+n0jcBPWxKRNY07n2ssm9NtbsRwP/KtxJ3PQ8uUGCJiM/DD9M/MCiKvZ0DWmKz3MUwBvglMBcb0z4+IvVsUl5l1UF6Hu7DmyNr5fAHJ2cJG4K3AxcDPWxVUt8rrwdNwH/CrEg+QVhtvcxvL1l+0bbImhm0i4neAImJRRJwJHN26sKwZPEBajWWbF0ZuFLG+GrlyLK/bXKusnc/Pp0NuP5wOc7EU2L51YXWXPGT4Sgp5XX6njuTyWV3D/si3ko5dsZajGst6xnAasC3wWeB1wAnAia0Kqlvl9YKEIh4VNqKI9VXEbW7EcK+vIc8Y0pvZPhARpwNrgI+0PKou5T6G/HD7cW0Kuc0du0u++w15xhARm4A3tiEWazL3MdRYtnlh5EYR68t9DENTlvY2ST8keSznlcCz/fMj4urWhVbZ9OnTo6en4kjfQ5q7eCWz5j3Oj29ZyD+8ZR9+dMsjLyz7zrGv5fQr5/LVo1/J1699sOp7HPu6Cfz+oWVIsHLtBjZuDo5+zZ5ce9/jVcv0O/3wl7Hf+B35l/8/n4VPJdW4w+iRIDjt0Cmcc/0C1m/aXLHsx984mRsffJJFT68tm/+mKWOZPHY77lq4nAVPrmbrEVtt8R47jB7JHjuOYdvRI1m6Yi1PrVkPwAkHvZT7l6xiv/E78ou7/sqoEWLDpi33hzfsuyu395aPhr7vbtvzSN8azjrmVfzTNfOqbvMn3rI3V8xezIq1G9jjJWN44pl1vHbCjsxdsopvvPdVfOXX1ct+9tAp/PzORSx/dn3Z/Cm7bc/Dy9bwvgPGc9A+u3LO9Q+9sE393vaK3fj9Q+WPEL/7n97OVoL9z3rxESKV6qt/+3qXrSmbd+LBe3HRHYs4+U2T+cmtjzJiK7Fp85b19f7XTeCqOUv4+4P24pI7FwFw9Kv35Nr7H2f8Tttw8D67ctWcJRW3+dNv3Ydzb3qk4rKvHv1KzrlhAes3Vt9Hfnrbo1vM/8GHpvGpS+8edJu323oEo0eNYPmz69n9JaN58pnny5ZvM2oEz23YVHUfedsrduOvy9eyw5iR3PPXZFi1s9/3amZcfX/FWEv1fxf7/18BDt57V162+/ZcdMeiQct+9tApfP93DzNm1FZcfsrBvOfc2wG49rNv5Ojv3/bCeiO3EhsH/F+99eXj+MPDT7Fpc/CTD0/n5IuT35XrP/cmTjp/Nque28BzGzYNuY/8x/EH8JnL7gHghx+axk9uXciKtRt49KlntyjT79jXTeDKOUv43GFT+LffPgwk+8iYUSPo7VvD3MUrtyjzkTdM4p+OnspWW9WXniTNGWw07LJ1MyaGCyrMjoj4aK3BNaqRxDBpxrVNjsby5J2v2ZMHH3+GR/qqf2HNutklHzuQN02p7/HGtSSGrHc+F7ZfwYaP9Rs389z6TZ0Ow6xuFU5QWyLrnc8XUKHPpBNnDGZm1lpZ72P4TcnrMcB7gceaH46ZmXVa1qakX5VOS7oMuK3K6mZmlmNZb3AbaAqwWzMDMTOz7pC1j2E15X0MT5A8o8HMzIaZrE1JO7Q6EDMz6w6ZmpIkvVfSjiXTO0l6T+vCMmu+PAxFYNYNsvYxfC0iVvVPRMRK4GutCcnMzDopa2KotF7WS13NuobPGsyGljUx9Ej6rqR90r/vAnNaGZhZs+V1dFyzdsuaGD4DrAd+CVwOrAM+3aqgzFqlKKNjmjUi61VJzwIzWhyLmZl1gaxXJd0oaaeS6Z0l3dC6sMxawW1JZllkbUoam16JBEBErMB3PlvOuI/BLJusiWGzpJf2T0iahA+/zMyGpayJ4SvAbZIukfRz4Bbgy0MVknSEpAWSeiVV7aOQ9HeSQlKmh0iY1cNHMmbZZEoMEXE9MB1YAFwGfB54brAykkYA5wJHAlOB4yVNrbDeDsBpwF01RW5mZi2RdRC9j5P8eE8A7gUOAu4A3jZIsQOB3ohYmL7H5cAxwPwB6/0L8C3gCzVFblajLI+xNbPsTUmnAa8HFkXEW4EDgC2fVl1uPLC4ZHpJOu8FkqYBEyNi0IcxSzpFUo+knr6+vowhm5lZPbImhnURsQ5A0uiIeAh4eSMfLGkr4LskzVKDiojzImJ6REwfN66+B2GbgfsZzLLIOt7RkvQ+hmuAGyWtABYNUWYpMLFkekI6r98OwKuAmyUB7AHMlPTuiOjJGJdZZk4KZtlkvfP5venLMyXdBOwIXD9EsdnAFEmTSRLCccAHS95zFTC2f1rSzcDpTgrWSh4Sw2xoNY+QGhG3ZFxvo6RTgRuAEcD5EfGApLOAnoiYWetnm5lZ67V06OyImAXMGjDvjCrrHtLKWMx8UZJZNlk7n83MrCCcGKwwfMJglo0TgxWGb3Azy8aJwczMyjgxmJlZGScGMzMr48RgheJeBrOhOTFYYbjv2SwbJwYzMyvjxGCFEW5IMsvEicEKxYPomQ3NicHMzMo4MVhhuPPZLBsnBjMzK+PEYIXhMwazbJwYzMysjBODFYYvVzXLxonBCsWpwWxoTgxWGO5jMMvGicHMzMo4MVhh+ITBLBsnBisUD4lhNjQnBjMzK+PEYMXhtiSzTJwYzMysjBODFYZvcDPLxonBzMzKODFYYfgGN7NsnBjMzKyME4MVhk8YzLJpaWKQdISkBZJ6Jc2osPwfJc2XdJ+k30naq5XxmDk5WJ616wbNliUGSSOAc4EjganA8ZKmDljtHmB6RLwGuAo4p1XxmIU7GSzn2rUHt/KM4UCgNyIWRsR64HLgmNIVIuKmiFibTt4JTGhhPGZmlkErE8N4YHHJ9JJ0XjUfA66rtEDSKZJ6JPX09fU1MUQrEp8vmGXTFZ3Pkk4ApgPfrrQ8Is6LiOkRMX3cuHHtDc6GFQ+iZza0kS1876XAxJLpCem8MpIOA74CvCUinm9hPGZmlkErzxhmA1MkTZa0NXAcMLN0BUkHAD8G3h0Ry1oYi5lvcDPLqGWJISI2AqcCNwAPAldExAOSzpL07nS1bwPbA1dKulfSzCpvZ2ZmbdLKpiQiYhYwa8C8M0peH9bKzzcr5RMGs2y6ovPZzMy6hxODFYc7GcwycWKwQnFqsDzL/ZAYZmaWT04MVhg+WzDLxonBzMzKODFYoXhIDLOhOTFYYfiiJMu74TDstllXCfcymGXixGCF4tRgNjQnBisMNyWZZePEYIXi5GA2NCcGKwwnBbNsnBisUNwBbTY0JwYzs5yINp32OjFYYQRuTjLLwonBzCwnfIObWZNFuIfBLAsnBjOzvGjTkY0Tg5mZlXFisEJx57PlWbsaQ50YrDCcFMyycWKwgnF2sPxq18GNE4MVhq9JMsvGicEKxc1JZkNzYjAzywk3JZk1WYR7GMyycGIwM8sJD4lh1mTJIHo+ZzAbihODmVlOeNhtsybzIHpm2bQ0MUg6QtICSb2SZlRYPlrSL9Pld0ma1Mp4zMzyLPd9DJJGAOcCRwJTgeMlTR2w2seAFRGxL/A94FutisfMzLJp5RnDgUBvRCyMiPXA5cAxA9Y5BrgofX0VcKgktSKYK2YvbsXbWo480vcsK9du6HQYZnW7vfeptnxOKxPDeKD013hJOq/iOhGxEVgF7DrwjSSdIqlHUk9fX19dwey07SheM2HHF6Z3GD2ybPmU3bYHYJfttq7r/bMav9M2FeePGZXP7p6B9ViLZtT1tluPyLzuO/bbncNeuVvDn9kpo0fWt4/steu2TY4km21GZf+/aYbXlny/p710p5rK7j/xxfX/1z5b/AQNateS/Xjy2O1qKlurw165e0vfv1/93+o2iojzgPMApk+fXlcz2+H77cHh++3R1LjMzIajVh6mLgUmlkxPSOdVXEfSSGBH4OkWxmRmZkNoZWKYDUyRNFnS1sBxwMwB68wETkxfvx/4ffgOJDOzjmpZU1JEbJR0KnADMAI4PyIekHQW0BMRM4GfAZdI6gWWkyQPMzProJb2MUTELGDWgHlnlLxeBxzbyhjMzKw2+bwUxszMWsaJwczMyjgxmJlZGScGMzMro7xdHSqpD1hUZ/GxQHvuKW+evMWct3ghfzHnLV7IX8x5ixeGjnmviBiX5Y1ylxgaIaknIqZ3Oo5a5C3mvMUL+Ys5b/FC/mLOW7zQ3JjdlGRmZmWcGMzMrEzREsN5nQ6gDnmLOW/xQv5izlu8kL+Y8xYvNDHmQvUxmJnZ0Ip2xmBmZkNwYjAzszKFSQySjpC0QFKvpBmdjqefpL9Iul/SvZJ60nm7SLpR0sPpvzun8yXp++k23CdpWptiPF/SMknzSubVHKOkE9P1H5Z0YqXPamG8Z0pamtbzvZKOKln25TTeBZLeUTK/bfuMpImSbpI0X9IDkk5L53dlPQ8Sb9fWs6Qxkv4kaW4a8z+n8ydLuiv9/F+mjwlA0uh0ujddPmmobWlTvBdKerSkjvdP5zdvn4iIYf9HMuz3I8DewNbAXGBqp+NKY/sLMHbAvHOAGenrGcC30tdHAdcBAg4C7mpTjG8GpgHz6o0R2AVYmP67c/p65zbGeyZweoV1p6b7w2hgcrqfjGj3PgPsCUxLX+8A/DmNrSvreZB4u7ae07raPn09CrgrrbsrgOPS+T8CPpm+/hTwo/T1ccAvB9uWNsZ7IfD+Cus3bZ8oyhnDgUBvRCyMiPXA5cAxHY5pMMcAF6WvLwLeUzL/4kjcCewkac9WBxMRfyB5XkYjMb4DuDEilkfECuBG4Ig2xlvNMcDlEfF8RDwK9JLsL23dZyLi8Yi4O329GniQ5JnoXVnPg8RbTcfrOa2rNenkqPQvgLcBV6XzB9Zxf91fBRwqSYNsS7viraZp+0RREsN4YHHJ9BIG34nbKYD/ljRH0inpvN0j4vH09RNA/xPAu2k7ao2xG2I/NT3FPr+/SWaQuDoWb9pkcQDJEWLX1/OAeKGL61nSCEn3AstIfiAfAVZGxMYKn/9CbOnyVcCu7Yx5YLwR0V/H30jr+HuSRg+Md0BcNcdblMTQzd4YEdOAI4FPS3pz6cJIzgW7+priPMQI/BDYB9gfeBz4186GU5mk7YFfAZ+LiGdKl3VjPVeIt6vrOSI2RcT+JM+gPxB4RYdDGtTAeCW9CvgySdyvJ2ke+lKzP7coiWEpMLFkekI6r+MiYmn67zLg1yQ765P9TUTpv8vS1btpO2qNsaOxR8ST6ZdsM/ATXjz175p4JY0i+ZG9NCKuTmd3bT1XijcP9ZzGuRK4CTiYpMml/2mWpZ//Qmzp8h2BpzsRc0m8R6TNeBERzwMX0II6LkpimA1MSa8+2JqkI2lmh2NC0naSduh/DRwOzCOJrf/KgROB/0pfzwQ+nF59cBCwqqSZod1qjfEG4HBJO6fNC4en89piQF/Me0nquT/e49IrUCYDU4A/0eZ9Jm27/hnwYER8t2RRV9ZztXi7uZ4ljZO0U/p6G+DtJH0jNwHvT1cbWMf9df9+4PfpWVu1bWlHvA+VHCiIpD+ktI6bs0/U22Oetz+SHvs/k7QpfqXT8aQx7U1ydcNc4IH+uEjaMX8HPAz8FtglXrxK4dx0G+4HprcpzstImgU2kLRPfqyeGIGPknTU9QIfaXO8l6Tx3Jd+gfYsWf8rabwLgCM7sc8AbyRpJroPuDf9O6pb63mQeLu2noHXAPeksc0Dzkjn703yw94LXAmMTuePSad70+V7D7UtbYr392kdzwN+zotXLjVtn/CQGGZmVqYoTUlmZpaRE4OZmZVxYjAzszJODGZmVsaJwczMyjgxWGFJ+mP67yRJH2zye//fSp9llge+XNUKT9IhJHDIugEAAAHZSURBVCOCvrOGMiPjxfF1Ki1fExHbNyM+s3bzGYMVlqT+kSvPBt6Ujm3/f9KBy74taXY6UNkn0vUPkXSrpJnA/HTeNekAiA/0D4Io6Wxgm/T9Li39rPSu1G9LmqfkORwfKHnvmyVdJekhSZemd7aatd3IoVcxG/ZmUHLGkP7Ar4qI16cjV94u6b/TdacBr4pkuGWAj0bE8nTIgtmSfhURMySdGsngZwO9j2SAudcCY9Myf0iXHQDsBzwG3A68Abit+ZtrNjifMZht6XCSMWfuJRlKeleS8XAA/lSSFAA+K2kucCfJQGVTGNwbgcsiGWjuSeAWklEy+997SSQD0N0LTGrK1pjVyGcMZlsS8JmIKBtoLO2LeHbA9GHAwRGxVtLNJOPr1Ov5kteb8PfTOsRnDGawmuTxlP1uAD6ZDiuNpJelo98OtCOwIk0KryB5nGK/Df3lB7gV+EDajzGO5DGkTR+Z06wRPiIxS0av3JQ2CV0I/DtJM87daQdwHy8+7rHU9cA/SHqQZJTNO0uWnQfcJ+nuiPhQyfxfkzwDYC7J6KRfjIgn0sRi1hV8uaqZmZVxU5KZmZVxYjAzszJODGZmVsaJwczMyjgxmJlZGScGMzMr48RgZmZl/gck6DzWLbqQEgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}